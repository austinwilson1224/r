---
title: Predicting the interest rate
date: 8 November 2020
---

Our goal in this assignment is to predict the interest rate of government debt as accurately as possible.


#### Outcomes

- Fit statistical learning models to multivariate data
- Create numeric variables from character vectors
- Compare test set performance of different models


#### Instructions

- Answer the following questions, and show all your R code.
- Upload your submission to Canvas in nicely formatted HTML generated from Rstudio.


### Data

_The [California DebtWatch](https://data.debtwatch.treasurer.ca.gov/Raw-Data/CDA-ALL-Raw/x7jp-pweb) contains the following information:_

> The principal amounts, sale dates, interest rates, terms, purposes, ratings, costs of issuance, financing team participants, issuance documents, and annual reporting (if applicable), among 67 other data points required under California Government Code section 8855, of the various types of debt issued by all state and local government agencies in California.

_Download the data in CSV format and load it into R.
Randomly select 20% of the rows and save them into a test set to use later to evaluate the performance of your model.
Which column(s) represent interest rate?_


```{r}
set.seed(280)
data = read.csv("/Users/austinwilson/coding/r/assignment9/CDA_ALL_Raw.csv")
# randomize data
data = data[sample(nrow(data)),]
# size of the train and test set
train_size = floor(dim(data)[1] * .8)
test_size = dim(data)[1] - train_size
# subset data to get train and test sets  
train = head(data,train_size)
test = tail(data,test_size)
# find interest rate 
interest = grep("Interest", colnames(data), value = TRUE)
interest
```


### Calculated Columns

_Define one or more new columns from existing text columns in the data set.
For example, you could add a logical column indicating whether the term "lease" appears in some column.
Why do you think this new column will help you improve the accuracy of your model?_

```{r}
data$lease <- sapply(colnames(data), function(x) grepl("lease", data[,x]))
```


### Models

_Use the remaining 80% of the data (the training set) to come up with two different models to predict interest rate.
You're welcome to use any external machine learning libraries you like, or you can stick with the `lm` and `rpart` from class.
Note that you can come up with different models by using different subsets of columns.
For example, a model with 3 input columns differs from a model with 60 input columns.
Briefly describe the two models you ended up with._

```{r}
# this is just to print out which columns are numeric 
numeric_columns_ = c()
for (column in colnames(data)) {
  if (class(data[,column])[1] == "numeric") {
    # print(column)
    numeric_columns_ = c(numeric_columns_,column)
  }
}
numeric_columns_
```


```{r}
# I have manually identified which columns have the least na values (might be a better way to do it) 
numeric_columns_with_most_data = c("TIC.Interest.Rate", "Principal.Amount", "New.Money", "Refunding.Amount", "Issue.Costs.Pct.of.Principal.Amt", "Total.Issuance.Costs", "UW.Total.Discount.Spread")

# trying to create the largest subset with no na values 
test1 = test[,numeric_columns_with_most_data]
test1 = na.omit(test1)

test = test[,numeric_columns]
test = na.omit(test)

train1 = train[,numeric_columns_with_most_data]
train1 = na.omit(train1)

train = train[,numeric_columns]
train = na.omit(train)



model = lm(TIC.Interest.Rate ~ ., data = train)
model1 = lm(TIC.Interest.Rate ~ Principal.Amount + New.Money + Refunding.Amount + Issue.Costs.Pct.of.Principal.Amt + Total.Issuance.Costs + UW.Total.Discount.Spread, data = train1)
model2 = lm(TIC.Interest.Rate ~ Principal.Amount + New.Money + Refunding.Amount + Net.Issue.Discount.Premium, data = train)
model3 = rpart(TIC.Interest.Rate ~ Principal.Amount + New.Money + Refunding.Amount + Net.Issue.Discount.Premium, data = train)
model4 = 

summary(model1)
summary(model2)
summary(model3)
```


### Evaluating Performance

_Evaluate both of your models on the 20% of the data you reserved for the test set by looking at the average absolute difference between the interest rate predicted by the model and the actual interest rate.
Do the models do a reasonable job of predicting interest rate?
Find the rows where the predicted interest rate is farthest from the true interest rate.
Why might the model have done a poor job on these rows?_

```{r}
# before test has 13409 rows
# before train has 53634 rows
# use na.omit 
test = na.omit(test)
# train = na.omit(train)
average_absolute_difference = function(predicted, actual) {
  length = length(predicted)
  difference = predicted - actual
  difference_squared = difference ** 2
  absolute_difference = sqrt(difference_squared)
  sum(absolute_difference, na.rm = TRUE) / length
}


prediction1 = predict(model1, test, na.rm = TRUE)
aad1 = average_absolute_difference(prediction1, test$TIC.Interest.Rate)
aad1

prediction2 = predict(model2, test, na.rm = TRUE)
aad2 = average_absolute_difference(prediction2, test$TIC.Interest.Rate)
aad2


prediciton3 = predict(model3, test, na.rm = TRUE)
aad3 = average_absolute_difference(prediciton3, test$TIC.Interest.Rate)
aad3

sort(which(test$TIC.Interest.Rate > prediction1))

test[5,]

```