{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# stat 128 final project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"\"\n",
    "path_test = \"\"\n",
    "path_to_model = '/Users/austinwilson/coding/r/final-project/waste-recognition/models/'\n",
    "model_name = \"\"# 'model_simple4.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_image_array(path, img_size = (128,128)):\n",
    "    image_names_o = os.listdir(path + \"/O\")\n",
    "    image_names_r = os.listdir(path + \"/R\")\n",
    "    numpy_img_array_o = []\n",
    "    numpy_img_array_r = []\n",
    "\n",
    "    # for the images in O category \n",
    "    for img_name in image_names_o:\n",
    "        # some images in grey scale\n",
    "        img = Image.open(path + \"/O/\" + img_name).convert(\"RGB\")\n",
    "        img = img.resize(img_size)\n",
    "        img_array = np.asarray(img)\n",
    "        if img.size == (128,128):\n",
    "            numpy_img_array_o.append(img_array)\n",
    "\n",
    "    # for the images in R category \n",
    "    for img_name in image_names_r:\n",
    "        # some images in grey scale\n",
    "        img = Image.open(path + \"/R/\" + img_name).convert(\"RGB\")\n",
    "        img = img.resize(img_size)\n",
    "        img_array = np.asarray(img)\n",
    "        if img.size == (128,128):\n",
    "            numpy_img_array_r.append(img_array)\n",
    "\n",
    "\n",
    "\n",
    "    return np.asarray(numpy_img_array_o, dtype=\"float64\"), np.asarray(numpy_img_array_r, dtype=\"float64\")"
   ]
  },
  {
   "source": [
    "## getting images into a numpy array for training/test and organic/recycle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "organic_images_train, recyclable_images_train = get_numpy_image_array(path_train)\n",
    "organic_images_test, recyclable_images_test = get_numpy_image_array(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([organic_images_train,recyclable_images_train])\n",
    "x_test = np.concatenate([organic_images_test,recyclable_images_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_organic_train = np.repeat(\"O\",len(organic_images_train))\n",
    "y_recycle_train = np.repeat(\"R\",len(recyclable_images_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_organic_test = np.repeat(\"O\",len(organic_images_test))\n",
    "y_recycle_test = np.repeat(\"R\",len(recyclable_images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_organic_train,y_recycle_train])\n",
    "y_test = np.concatenate([y_organic_test,y_recycle_test])"
   ]
  },
  {
   "source": [
    "confirm size "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_1 = LabelEncoder()\n",
    "y_train = le_1.fit_transform(y_train)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "le_2 = LabelEncoder()\n",
    "y_test = le_2.fit_transform(y_test)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=2,verbose=2,mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=path_to_model+model_name,verbose=0,save_best_only=True)\n",
    "# checkpointer256 = ModelCheckpoint(filepath='/content/drive/My Drive/180/final project/dnn/modelo256.hdf5',verbose=0,save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training!!\n",
    "for i in range(5):\n",
    "    model_simple.fit(x_train ,y_train,\n",
    "                    batch_size = 20,\n",
    "                    epochs = 20,\n",
    "                    verbose=2,\n",
    "                    callbacks=[monitor, checkpointer],\n",
    "                    validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test,axis = 1)\n",
    "y_pred = model_simple.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "report = metrics.classification_report(y_true,y_pred)\n",
    "\n",
    "f1_simple = metrics.f1_score(y_true,y_pred,average='weighted')\n",
    "f1_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_128 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "model_19_128 = Sequential()\n",
    "for layer in vgg19_128.layers:\n",
    "  model_19_128.add(layer)\n",
    "for layer in model_19_128.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "model_19_128.add(Flatten())\n",
    "model_19_128.add(Dense(2,activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_vgg19_128 = ModelCheckpoint(filepath='path_to_model/vgg19_1.hdf5',verbose=0,save_best_only=True)\n",
    "monitor = EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=2,verbose=2,mode='auto')\n",
    "model_19_128.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in range(5):\n",
    "model_19_128.fit(x_train,y_train,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            verbose=2,\n",
    "            callbacks=[monitor,checkpointer_vgg19_128],\n",
    "            validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test,axis = 1)\n",
    "y_pred = model_19_128.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "f1_vgg19 = metrics.f1_score(y_true,y_pred,method=\"weighted\")"
   ]
  }
 ]
}